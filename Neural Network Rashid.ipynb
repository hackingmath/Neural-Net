{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here it is\n",
      "[[0.01445886]\n",
      " [0.98313379]\n",
      " [0.03758832]\n",
      " [0.0407742 ]\n",
      " [0.0060764 ]\n",
      " [0.03042195]\n",
      " [0.00385027]\n",
      " [0.05512058]\n",
      " [0.07337665]\n",
      " [0.00487963]]\n",
      "finished?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"a = np.zeros([3,2])\\na[0,0] = 1\\na[0,1] = 2\\na[1,0] = 9\\na[2,1] = 12\\n\\nplt.imshow(a, interpolation = 'nearest')\\nplt.show()\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Make your own Neural Network\n",
    "Tariq Rashid\n",
    "May 30, 2017'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import exp\n",
    "#import scipy.special\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "\n",
    "    #initialize the neural network\n",
    "    def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.onodes = outputnodes\n",
    "\n",
    "        #link weight matrices, wih and who\n",
    "        #weights inside the arrays are w_i_j, where link\n",
    "        #is from node i to node j in the next layer\n",
    "        #w11 w21\n",
    "        #w12 w22 etc\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5),\n",
    "                                       (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5),\n",
    "                                       (self.onodes, self.hnodes))\n",
    "        \n",
    "        #learning rate\n",
    "        self.lr = learningrate\n",
    "        pass\n",
    "\n",
    "    def activation_function(self,x):\n",
    "        #activation function is the sigmoid function\n",
    "        out = np.zeros([len(x),1])\n",
    "        for i,element in enumerate(x):\n",
    "            #print(\"element: \",element)\n",
    "            out[i] = sigmoid(x[i][0])\n",
    "            #print(out)\n",
    "        return out\n",
    "\n",
    "    #train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "\n",
    "        #calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        #calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        #calculate signals entering final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        #calculate signals exiting final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "\n",
    "        #output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        #hidden layer error is the output_errors, split by weights,\n",
    "        #recombined at hidden nodes\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "\n",
    "        #update the weights for the links between the\n",
    "        #hidden and output layers\n",
    "        self.who += self.lr * np.dot((output_errors * final_outputs *\\\n",
    "                                      (1.0 - final_outputs)),\n",
    "                                     np.transpose(hidden_outputs))\n",
    "\n",
    "        #update the weights for the links between the input\n",
    "        #and hidden layers\n",
    "        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs *\\\n",
    "                                      (1.0 - hidden_outputs)),\n",
    "                                     np.transpose(inputs))\n",
    "        pass\n",
    "\n",
    "    #query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        #convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list,ndmin=2).T\n",
    "\n",
    "        #calculate signals into hidden layer\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        #calculate the signals emerging from the\n",
    "        #hidden layer\n",
    "        #print(\"Hidden inputs:\", hidden_inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "\n",
    "        #calculate signals into final output layer\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        #calculate the signals emerging from final\n",
    "        #output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        #print(\"final_outputs: \",final_outputs)\n",
    "        return final_outputs\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1/(1+exp(-t))\n",
    "\n",
    "#number of input, hidden and output nodes\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.3\n",
    "\n",
    "#create instance of neural network\n",
    "n = NeuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "#load the mnist training data CSV file into a list\n",
    "training_data_file = open('mnist_train_100.csv','r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()\n",
    "\n",
    "#train the neural network\n",
    "#go through all records in training data set\n",
    "for record in training_data_list:\n",
    "    #split the record by the commas\n",
    "    all_values = record.split(',')\n",
    "    #scale and shift the inputs\n",
    "    inputs = (np.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "    #create the target output values (all 0.01 except the\n",
    "    #desired label which is 0.99)\n",
    "    targets = np.zeros(output_nodes) + 0.01\n",
    "    #print(\"all values[0]: \",all_values[0])\n",
    "    #print(\"targets: \",targets)\n",
    "    #all values[0] is the target label for this record\n",
    "    targets[int(all_values[0])] = 0.99\n",
    "    n.train(inputs,targets)\n",
    "    pass\n",
    "\n",
    "#load the mnist data csv file into a list\n",
    "test_data_file = open('mnist_test_10.csv','r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()\n",
    "\n",
    "###TO TEST###\n",
    "#get the first test record\n",
    "all_values = test_data_list[5].split(',')\n",
    "#print the label\n",
    "print(all_values[0])\n",
    "image_array = np.asfarray(all_values[1:]).reshape((28,28))\n",
    "plt.imshow(image_array, cmap=\"Greys\", interpolation='None')\n",
    "plt.show()\n",
    "\n",
    "print(\"here it is\")\n",
    "print(n.query((np.asfarray(all_values[1:]) / 255 * 0.99) + 0.01))\n",
    "print(\"finished?\")\n",
    "\n",
    "'''a = np.zeros([3,2])\n",
    "a[0,0] = 1\n",
    "a[0,1] = 2\n",
    "a[1,0] = 9\n",
    "a[2,1] = 12\n",
    "\n",
    "plt.imshow(a, interpolation = 'nearest')\n",
    "plt.show()'''\n",
    "\n",
    "#print(n.query([1.0, 0.5, -1.5]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a649b509054f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
